# Qwen2.5-7B-Instruct Agent 微调计划文档

本目录包含了对 Qwen2.5-7B-Instruct 模型进行 Agent 数据全量微调的完整计划和指南。

## 📚 文档导航

### 1. 🚀 [快速开始指南](./quick_start.md)
**适合人群**：想快速了解整个流程的用户

**包含内容**：
- 快速检查清单
- 关键配置参数速查表
- 常用命令集合
- 常见问题快速解决方案

**推荐阅读时间**：15 分钟

---

### 2. 📋 [完整微调计划](./qwen2_5_agent_finetuning_plan.md)
**适合人群**：需要详细了解整个微调流程的用户

**包含内容**：
- 项目概述和目标
- 第一阶段：数据转化（详细步骤）
- 第二阶段：训练配置（完整配置文件示例）
- 第三阶段：执行训练（命令和监控）
- 关键注意事项和时间估计
- 数据转化脚本示例
- 常见问题排查
- 训练后评估方法

**推荐阅读时间**：1-2 小时

---

### 3. 🔄 [数据转化详细指南](./data_conversion_guide.md)
**适合人群**：需要详细了解数据转化过程的用户

**包含内容**：
- 原始数据格式示例
- ShareGPT 格式转化示例
- 数据验证检查清单
- 批量转化脚本（完整代码）
- 数据验证脚本（完整代码）
- 数据集注册方法
- 执行转化的具体命令

**推荐阅读时间**：1 小时

---

### 4. 📖 [ShareGPT 格式与 Loss Mask 指南](../sharegpt_tools_and_loss_mask_guide.md)
**适合人群**：需要深入理解 ShareGPT 格式和 Loss Mask 机制的用户

**包含内容**：
- 工具定义转化为 ShareGPT 格式的完整流程
- Loss Mask 的实现细节和配置方法
- reasoning_content 的支持情况
- 代码实现细节和参考位置
- 常见问题解答
- 最佳实践建议

**推荐阅读时间**：1-2 小时

---

## 🎯 推荐阅读顺序

### 场景 1：快速上手
1. 📖 快速开始指南 (15 分钟)
2. 🔄 数据转化详细指南 (1 小时)
3. 📋 完整微调计划 (1-2 小时)

**总耗时**：2.5-3.5 小时

### 场景 2：深入理解
1. 📖 快速开始指南 (15 分钟)
2. 📖 ShareGPT 格式与 Loss Mask 指南 (1-2 小时)
3. 🔄 数据转化详细指南 (1 小时)
4. 📋 完整微调计划 (1-2 小时)

**总耗时**：4-5.5 小时

### 场景 3：仅需参考
- 📖 快速开始指南 (15 分钟)
- 需要时查阅其他文档

---

## 📊 项目结构

```
docs/plan/
├── README.md                          # 本文件
├── quick_start.md                     # 快速开始指南
├── qwen2_5_agent_finetuning_plan.md  # 完整微调计划
├── data_conversion_guide.md           # 数据转化详细指南
└── ../sharegpt_tools_and_loss_mask_guide.md  # ShareGPT 格式指南
```

---

## 🔑 关键概念速览

### ShareGPT 格式
LLaMA-Factory 的标准对话格式，支持多角色（human, gpt, function_call, observation）

### Loss Mask
通过 IGNORE_INDEX (-100) 标记不参与损失计算的 token，实现灵活的训练策略

### Reasoning Content
通过 `<think>...</think>` 标签实现思维链，支持 `enable_thinking` 参数控制是否计算损失

### Tool Calling
模型调用工具的能力，通过 function_call 角色和工具定义实现

### Agent 能力
综合工具调用、推理和决策的能力，使模型能够自主规划和执行任务

---

## 📈 项目时间表

| 阶段 | 任务 | 预计时间 | 文档参考 |
|------|------|--------|--------|
| 准备 | 数据收集和格式化 | 1-2 天 | 数据转化详细指南 |
| 转化 | 数据转化和验证 | 0.5-1 天 | 数据转化详细指南 |
| 配置 | 训练配置准备 | 0.5 天 | 完整微调计划 |
| 训练 | 模型微调 | 3-7 天 | 完整微调计划 |
| 评估 | 模型评估和测试 | 1-2 天 | 完整微调计划 |
| **总计** | - | **6-12.5 天** | - |

---

## ✅ 前置条件检查

在开始之前，请确保满足以下条件：

- [ ] 已安装 LLaMA-Factory
- [ ] 有 Agent 数据集（包含工具定义、推理过程）
- [ ] GPU 显存 >= 40GB（推荐使用多卡）
- [ ] Python >= 3.10
- [ ] 熟悉 YAML 配置文件格式
- [ ] 了解基本的 JSON 格式

---

## 🚀 快速开始

```bash
# 1. 进入项目目录
cd /home/yulan_pretrain/lvzhihao/LLaMA-Factory

# 2. 准备数据
python scripts/convert_agent_data.py
python scripts/validate_sharegpt_data.py

# 3. 启动训练
python src/train.py examples/train_full/qwen2_5_agent_full_sft.yaml

# 4. 测试模型
python src/api.py --model_name_or_path saves/qwen2_5-7b/agent/full/sft
```

---

## 💡 关键提示

1. **数据质量最重要**：确保推理过程逻辑清晰，工具调用准确
2. **从小到大**：先用小数据集验证流程，再用全量数据
3. **监控训练**：定期检查 loss 曲线和生成质量
4. **保存检查点**：定期保存训练检查点以便恢复
5. **充分评估**：训练后进行全面的工具调用和推理质量评估

---

## 📞 获取帮助

### 常见问题
- 查看各文档中的"常见问题"部分
- 查看"快速开始指南"中的常见问题速解

### 详细排查
- 查看"完整微调计划"中的常见问题排查部分
- 查看"ShareGPT 格式与 Loss Mask 指南"中的常见问题解答

### 代码参考
- 数据转化脚本：见"数据转化详细指南"
- 数据验证脚本：见"数据转化详细指南"
- 训练配置示例：见"完整微调计划"

---

## 📝 文档更新日志

- **2025-11-16**：初版发布
  - 创建快速开始指南
  - 创建完整微调计划
  - 创建数据转化详细指南
  - 创建本 README 文件

---

## 📄 许可证

本文档遵循 LLaMA-Factory 项目的许可证。


